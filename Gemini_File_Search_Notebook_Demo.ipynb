{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT5rH_mJ4VFs",
        "outputId": "2f0e34bd-df5a-4a00-d4f4-9cc41f969899"
      },
      "outputs": [],
      "source": [
        "!pip install google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TZMKQ4P84tyR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import glob\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"xxxx\"\n",
        "API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "FOLDER_PATH = \"my_docs\"\n",
        "STORE_NAME = \"rooms_reference_store\"\n",
        "MODEL_ID = \"gemini-2.5-flash\"\n",
        "\n",
        "client = genai.Client(api_key=API_KEY)\n",
        "\n",
        "def _get_metadata_logic(filename):\n",
        "    \"\"\"\n",
        "    Returns a simple dictionary.\n",
        "    \"\"\"\n",
        "    metadata = {\"status\": \"active\", \"uploaded_via\": \"script\"}\n",
        "\n",
        "    if \"invoice\" in filename.lower():\n",
        "        metadata[\"category\"] = \"finance\"\n",
        "    elif \"manual\" in filename.lower():\n",
        "        metadata[\"category\"] = \"technical\"\n",
        "    else:\n",
        "        metadata[\"category\"] = \"general\"\n",
        "\n",
        "    return metadata\n",
        "\n",
        "def upload_folder_and_get_ids(store_name, folder_path):\n",
        "    files = glob.glob(os.path.join(folder_path, \"*.*\"))\n",
        "    valid_files = [f for f in files if f.endswith(('.txt', '.pdf', '.csv', '.md', '.json'))]\n",
        "\n",
        "    database_records = {}\n",
        "\n",
        "    if not valid_files:\n",
        "        print(\"No files found.\")\n",
        "        return {}\n",
        "\n",
        "    print(f\"Uploading {len(valid_files)} files with metadata...\")\n",
        "\n",
        "    for file_path in valid_files:\n",
        "        filename = os.path.basename(file_path)\n",
        "\n",
        "        # 1. Get the simple dict\n",
        "        raw_meta = _get_metadata_logic(filename)\n",
        "\n",
        "        # 2. CONVERT DICT TO LIST OF CustomMetadata OBJECTS\n",
        "        # FIX: Use 'string_value' instead of 'value'\n",
        "        formatted_metadata = [\n",
        "            types.CustomMetadata(key=k, string_value=str(v))\n",
        "            for k, v in raw_meta.items()\n",
        "        ]\n",
        "\n",
        "        print(f\" > Processing: {filename} | Meta: {raw_meta}...\", end=\"\")\n",
        "\n",
        "        try:\n",
        "            operation = client.file_search_stores.upload_to_file_search_store(\n",
        "                file=file_path,\n",
        "                file_search_store_name=store_name,\n",
        "                config={\n",
        "                    'display_name': filename,\n",
        "                    'custom_metadata': formatted_metadata\n",
        "                }\n",
        "            )\n",
        "\n",
        "            while not operation.done:\n",
        "                time.sleep(1)\n",
        "                operation = client.operations.get(operation)\n",
        "\n",
        "            if hasattr(operation, 'result') and operation.result:\n",
        "                doc_id = operation.result.name\n",
        "                database_records[filename] = doc_id\n",
        "                print(f\" [Indexed] -> ID: {doc_id}\")\n",
        "            else:\n",
        "                print(\" [Error: No ID returned]\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" [Upload Failed]: {e}\")\n",
        "\n",
        "    return database_records\n",
        "\n",
        "def delete_store_completely(store_name):\n",
        "    \"\"\"\n",
        "    Deletes the store and all its contents (documents/chunks) in one go.\n",
        "    Using force=True prevents 'FAILED_PRECONDITION' errors for non-empty stores.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Cleanup: Deleting Store {store_name} ---\")\n",
        "\n",
        "    try:\n",
        "        # The 'force' parameter tells Gemini to cascade delete all files/chunks\n",
        "        client.file_search_stores.delete(\n",
        "            name=store_name,\n",
        "            config={'force': True}\n",
        "        )\n",
        "        print(\"   Store and all contained files deleted successfully.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   Error during deletion: {e}\")\n",
        "\n",
        "\n",
        "def print_citations(response):\n",
        "    \"\"\"\n",
        "    Parses the response to extract and print source filenames.\n",
        "    \"\"\"\n",
        "    if not response.candidates or not response.candidates[0].grounding_metadata:\n",
        "        return\n",
        "\n",
        "    metadata = response.candidates[0].grounding_metadata\n",
        "\n",
        "    # 1. Collect all unique sources used\n",
        "    unique_sources = {}\n",
        "\n",
        "    if metadata.grounding_chunks:\n",
        "        for i, chunk in enumerate(metadata.grounding_chunks):\n",
        "            # For File Search, data is in 'retrieved_context'\n",
        "            if chunk.retrieved_context:\n",
        "                title = chunk.retrieved_context.title or \"Unknown File\"\n",
        "                uri = chunk.retrieved_context.uri\n",
        "                unique_sources[i] = {'title': title, 'uri': uri}\n",
        "\n",
        "    # 2. Map supports to the text (Optional: detailed inline citation)\n",
        "    # This part shows which sentence came from which file\n",
        "    if metadata.grounding_supports:\n",
        "        print(\"\\n\" + \"=\"*20 + \" CITATIONS \" + \"=\"*20)\n",
        "        for support in metadata.grounding_supports:\n",
        "            # The text segment that needs a citation\n",
        "            segment_text = support.segment.text if support.segment else \"Answer\"\n",
        "\n",
        "            # The indices of the chunks that support this segment\n",
        "            indices = support.grounding_chunk_indices\n",
        "            # print(indices)\n",
        "\n",
        "            if indices:\n",
        "                files = [unique_sources.get(idx, {}).get('title') for idx in indices]\n",
        "                # Filter out None values just in case\n",
        "                files = list(set(filter(None, files)))\n",
        "\n",
        "                if files:\n",
        "                    print(f\"üìù CLAIM: \\\"...{segment_text.strip()[:50]}...\\\"\")\n",
        "                    print(f\"   ‚Ü≥ SOURCE: {', '.join(files)}\")\n",
        "                    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clUHOBT6rJet",
        "outputId": "255ce8f3-1d0b-4264-de38-24365c57b2a6"
      },
      "outputs": [],
      "source": [
        "# --- MAIN EXECUTION ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure dummy folder exists for testing\n",
        "    if not os.path.exists(FOLDER_PATH):\n",
        "        os.makedirs(FOLDER_PATH)\n",
        "        print(f\"Created '{FOLDER_PATH}'. Put files there and run again.\")\n",
        "        exit()\n",
        "\n",
        "    store_id = None\n",
        "    try:\n",
        "        # 1. Create Store\n",
        "        store = client.file_search_stores.create(config={'display_name': STORE_NAME})\n",
        "        store_id = store.name\n",
        "        print(f\"Store Created: {store_id}\")\n",
        "\n",
        "        # 2. Upload and Capture IDs for Database\n",
        "        # This returns the dictionary you requested\n",
        "        db_references = upload_folder_and_get_ids(store_id, FOLDER_PATH)\n",
        "\n",
        "        print(\"\\n--- IDs for your Database ---\")\n",
        "        for fname, fid in db_references.items():\n",
        "            print(f\"File: {fname} | Ref_ID: {fid}\")\n",
        "\n",
        "    finally:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoxOEw65j9MS",
        "outputId": "a27b7a4c-c3b4-41ec-89ec-9df0eb4ec460"
      },
      "outputs": [],
      "source": [
        "# --- 5. Generate Content (RAG) ---\n",
        "question = \"<search keywork or user query>\"\n",
        "print(f\"\\nAsking: '{question}'...\")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "            model=MODEL_ID,\n",
        "            contents=question,\n",
        "            config=types.GenerateContentConfig(\n",
        "                tools=[\n",
        "                    types.Tool(\n",
        "                        file_search=types.FileSearch(\n",
        "                            file_search_store_names=[store.name],\n",
        "                            metadata_filter=\"status=active\",\n",
        "                        )\n",
        "                    )\n",
        "                ]\n",
        "              )\n",
        "          )\n",
        "\n",
        "# 4. Print Answer\n",
        "print(\"GEMINI ANSWER:\")\n",
        "print(response.text)\n",
        "\n",
        "# 5. Print Citations\n",
        "print_citations(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dss-qcf4jE1x",
        "outputId": "aa9844f6-3bb6-4b6c-dd05-c8c76e6836d7"
      },
      "outputs": [],
      "source": [
        "# 4. Clean Delete (Fixes the 400 Error)\n",
        "if store_id:\n",
        "    delete_store_completely(store_id)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
